{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2793afa9-24c8-4ef2-b69c-724c4d042e67",
   "metadata": {},
   "source": [
    "# 1. Introduction to Ranking in Search Engines\n",
    "\n",
    "PageRank is a fundamental algorithm in the realm of search engines, and its development marked a significant advance in web search technology. Let's explore its inspiration, theoretical foundations, and the mathematics that underpin its operation.\n",
    "\n",
    "### Inspiration\n",
    "\n",
    "PageRank was developed by Larry Page and Sergey Brin in 1996 while they were Ph.D. students at Stanford University. The idea was sparked by the citation analysis method commonly used in academic publishing, where the significance of a paper is often judged by the number of citations it receives. Similarly, Page and Brin proposed that a webpage could be considered important if it was linked to by many other pages, and crucially, that those links from more significant pages should carry more weight.\n",
    "\n",
    "This approach was revolutionary because it shifted the focus from simply analyzing webpage content for keywords to evaluating the web's structure to determine relevance and importance.\n",
    "\n",
    "### Theoretical Foundations\n",
    "\n",
    "**Random Surfer Model:** At the heart of PageRank is the \"random surfer\" model, a stochastic process where a surfer randomly clicks on links but occasionally jumps to a random page. This model reflects a blend of deterministic and random behavior, mirroring how a human might browse the internet.\n",
    "\n",
    "**Teleportation:** The model includes a mechanism where a user can jump from any page to any other page with a small probability. This concept, often referred to as \"teleportation,\" ensures that the algorithm evaluates all parts of the graph and helps prevent rank sinks, where ranks could potentially accumulate in a tightly-knit community without outgoing links.\n",
    "\n",
    "### Mathematics of PageRank\n",
    "\n",
    "PageRank models the internet as a directed graph, where webpages are nodes, and hyperlinks are directed edges from one node to another. The rank of a page is determined through an iterative process based on the ranks of pages linking to it.\n",
    "\n",
    "**Equation:** The PageRank of a webpage $P$ can be defined by the equation:\n",
    "\n",
    "$$\n",
    "PR(P) = \\frac{1-d}{N} + d \\sum_{i \\in L(P)} \\frac{PR(i)}{C(i)}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ PR(P) $ is the PageRank of page $ P $,\n",
    "- $ d $ is the damping factor, typically set around 0.85, representing the probability that the surfer continues clicking links,\n",
    "- $ N $ is the total number of pages,\n",
    "- $ L(P) $ is the set of pages that link to $ P $,\n",
    "- $ C(i) $ is the number of outbound links on page $ i $.\n",
    "\n",
    "**Matrix Formulation:** Mathematically, PageRank can be represented as a problem of finding the principal eigenvector of the transition matrix of the web graph, modified by the damping factor. The matrix form of the PageRank equation is:\n",
    "\n",
    "$$\n",
    "\\mathbf{r} = d \\mathbf{M} \\mathbf{r} + \\frac{1-d}{N} \\mathbf{1}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ \\mathbf{r} $ is the vector of ranks of all pages,\n",
    "- $ \\mathbf{M} $ is the matrix where entry $ M_{ij} $ is $ 1/C(j) $ if there is a link from page $ j $ to page $ i $ (incoming link from $j$ to $i$) and zero otherwise,\n",
    "- $ \\mathbf{1} $ is a vector with all entries 1.\n",
    "\n",
    "**Convergence:** The iterative calculation of PageRank continues until the values converge â€” that is, the change in rank values between successive iterations becomes negligibly small. This convergence is guaranteed because the matrix operation involved is a form of power iteration, a well-known method in numerical linear algebra for finding dominant eigenvectors.\n",
    "\n",
    "The PageRank algorithm not only revolutionized search by providing a scalable and effective ranking method but also influenced numerous other fields, from social network analysis to systems biology, where the importance of nodes in a network needs to be assessed. Its mathematical elegance and practical effectiveness exemplify how ideas from theoretical computer science can be applied to solve real-world problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845d3905-035e-4c90-9f05-a7a29c798f6a",
   "metadata": {},
   "source": [
    "# 2. Python Code for PageRank\n",
    "\n",
    "Here, we'll implement PageRank using the matrix form of its equation. We'll use NumPy, a powerful library for numerical computations in Python, to handle matrices and vector operations efficiently.\n",
    "\n",
    "First, ensure you have NumPy installed in your Python environment. You can install it via pip if it's not already installed:\n",
    "\n",
    "```bash\n",
    "pip install numpy\n",
    "```\n",
    "\n",
    "Now, let's dive into the code:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "def pagerank(M, num_iterations=100, d=0.85):\n",
    "    \"\"\"Calculate the PageRank of each page in a transition matrix.\"\"\"\n",
    "    N = M.shape[1]  # Number of pages\n",
    "    v = np.ones(N) / N  # Initial probability distribution\n",
    "    M_hat = (d * M) + ((1 - d) / N * np.ones((N, N)))  # Adjusted matrix\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        v = np.matmul(M_hat, v)  # Update the rank vector\n",
    "\n",
    "    return v\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example transition matrix (weighted adjacency matrix), columns sum to 1 (column-stochastic matrix)\n",
    "    M = np.array([\n",
    "        [0.00, 0.50, 0.50, 0.00],\n",
    "        [0.33, 0.00, 0.00, 0.50],\n",
    "        [0.33, 0.50, 0.00, 0.50],\n",
    "        [0.33, 0.00, 0.50, 0.00]\n",
    "    ])\n",
    "\n",
    "    ranks = pagerank(M)\n",
    "    print(\"PageRank of each page:\", ranks)\n",
    "```\n",
    "\n",
    "### Explanation of the Code\n",
    "\n",
    "**Matrix Initialization (`M`):**\n",
    "- The matrix `M` represents the link structure of the web, where `M[j][i]` is the probability of moving from page `j` to page `i`. It's a column-stochastic matrix where each column sums to 1, reflecting the transition probabilities from one page to another. This directly corresponds to $ M_{ij} = \\frac{1}{C(j)} $ in the PageRank equation if page `j` has a link to page `i`.\n",
    "\n",
    "**Initial Rank Vector (`v`):**\n",
    "- The vector `v` starts as a uniform distribution, where each page is assigned an equal probability of $ \\frac{1}{N} $. This represents the initial assumption that no page is more important than another before the algorithm begins iterating.\n",
    "\n",
    "**Adjusted Matrix (`M_hat`):**\n",
    "- `M_hat` incorporates the damping factor `d` and adjusts for the random jump probability. The term `(d * M)` scales the transition probabilities by `d`, and `((1 - d) / N * np.ones((N, N)))` adds the probability of randomly jumping to any page (teleportation). This matrix directly implements the PageRank matrix formula: $$ \\mathbf{M}_{\\text{hat}} = d \\mathbf{M} + \\frac{1-d}{N} \\mathbf{1} \\mathbf{1}^T $$, where $ \\mathbf{1} $ is a vector of all ones, making the matrix stochastic.\n",
    "\n",
    "**Iteration to Convergence:**\n",
    "- The loop `for _ in range(num_iterations): v = np.matmul(M_hat, v)` repeatedly applies the PageRank formula, updating the rank vector `v` until it converges (or until the specified number of iterations is reached). Each multiplication step simulates a \"surfing\" process where the rank is passed along links, influenced by both following links and teleporting.\n",
    "\n",
    "This implementation highlights how the theoretical components of the PageRank formula are translated into a computational algorithm. Adjusting the number of iterations and damping factor allows you to experiment with convergence behavior and sensitivity to changes in the web graph structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c0ef85-486f-4b69-960e-f6eedf131c6c",
   "metadata": {},
   "source": [
    "# 3. Large Matrix\n",
    "When dealing with large matrices, such as an adjacency matrix of size 1,000 by 1,000 or larger, computational efficiency and memory usage become critical concerns. Here are several strategies to improve the performance of the PageRank algorithm implementation in Python, particularly when working with such large matrices:\n",
    "\n",
    "### 3.1 Sparse Matrix Representation\n",
    "Large web graphs typically result in sparse matrices, where most entries are zero because not every webpage links to every other webpage. Using a dense matrix representation in such cases is inefficient both in terms of computation and memory usage.\n",
    "\n",
    "**Solution:** Use the `scipy.sparse` module to store and manipulate sparse matrices efficiently. Operations on sparse matrices are much faster and use less memory when the matrix is sparse.\n",
    "\n",
    "```python\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "\n",
    "def pagerank_sparse(M, num_iterations=100, d=0.85):\n",
    "    N = M.shape[1]\n",
    "    v = np.ones(N) / N\n",
    "    M = csr_matrix(M)  # Convert M to a CSR (Compressed Sparse Row) matrix\n",
    "    M_hat = d * M + ((1 - d) / N) * np.ones((N, N))\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        v = M_hat.dot(v)\n",
    "\n",
    "    return v\n",
    "```\n",
    "\n",
    "### 3.2 Power Iteration Optimization\n",
    "Power iteration is a key step in the PageRank algorithm. Optimizing it can significantly enhance performance.\n",
    "\n",
    "**Solution:** Instead of fully recalculating the PageRank vector in each iteration, leverage convergence checks to stop iterations early when changes between iterations drop below a certain threshold.\n",
    "\n",
    "```python\n",
    "def pagerank_sparse_optimized(M, num_iterations=100, d=0.85, tol=1e-6):\n",
    "    N = M.shape[1]\n",
    "    v = np.ones(N) / N\n",
    "    M = csr_matrix(M)\n",
    "    M_hat = d * M + ((1 - d) / N) * np.ones((N, N))\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        v_new = M_hat.dot(v)\n",
    "        # Check if the change in the PageRank vector is below the tolerance\n",
    "        if np.linalg.norm(v_new - v, 1) < tol:\n",
    "            break\n",
    "        v = v_new\n",
    "\n",
    "    return v\n",
    "```\n",
    "\n",
    "### 3.3 Avoid Full Matrix Multiplications\n",
    "The adjustment of the matrix with the teleportation component can lead to full dense matrix operations, which are costly.\n",
    "\n",
    "**Solution:** Modify the matrix-vector multiplication to handle the teleportation part separately, thereby avoiding the creation of a full dense matrix.\n",
    "\n",
    "```python\n",
    "def pagerank_sparse_super_optimized(M, num_iterations=100, d=0.85, tol=1e-6):\n",
    "    N = M.shape[1]\n",
    "    v = np.ones(N) / N\n",
    "    M = csr_matrix(M)\n",
    "    teleport = (1 - d) / N * np.ones(N)\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        v_new = d * M.dot(v) + teleport\n",
    "        if np.linalg.norm(v_new - v, 1) < tol:\n",
    "            break\n",
    "        v = v_new\n",
    "\n",
    "    return v\n",
    "```\n",
    "\n",
    "### 3.4 Parallel and Distributed Computing\n",
    "For extremely large matrices, even optimized local computations might not be sufficient.\n",
    "\n",
    "**Solution:** Consider using parallel processing frameworks like Dask or PySpark to distribute the computation across multiple machines or cores.\n",
    "\n",
    "### 3.5 Efficient Use of Hardware\n",
    "Utilize hardware capabilities, such as multi-threading and advanced vectorization, to speed up calculations.\n",
    "\n",
    "**Solution:** Configure NumPy/SciPy to use optimized libraries like Intel MKL, which can significantly speed up matrix operations.\n",
    "\n",
    "By applying these strategies, you can significantly improve the performance of the PageRank computation, especially when dealing with large sparse matrices commonly found in web graph applications. Each of these methods reduces the computational burden, speeds up the algorithm, or both, making it feasible to handle large-scale problems more efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b25e8f-568a-4c3b-b858-b636abd37c94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
